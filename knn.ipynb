{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "knn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selahattinozturk/Urbansound-Classification/blob/main/knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SWNCDHdy9ud"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "CUR_PATH = '/content/drive/My Drive/EEE485'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg2M7EWLo811",
        "outputId": "af90e028-3e41-4f5e-a400-5c4e881dcbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"air_conditioner\", \"car_horn\", \"children_playing\", \"dog_bark\", \"drilling\", \"engine_idling\", \"gun_shot\", \"jackhammer\", \"siren\", \"street_music\"]\n",
        "class_idx = {c: i for i, c in enumerate(classes)}"
      ],
      "metadata": {
        "id": "IQImZ6dnpD8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_encoder(y_train):\n",
        "  onehot_y_train = []\n",
        "  for yi in y_train:\n",
        "    onehot_yi = [0 for i in range(len(classes))]\n",
        "    onehot_yi[class_idx[yi]] = 1\n",
        "    onehot_y_train.append(onehot_yi)\n",
        "\n",
        "  return np.array(onehot_y_train).copy()"
      ],
      "metadata": {
        "id": "KlE9_v2qpV07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def class2int(y_train):\n",
        "  onehot_y_train = []\n",
        "  for yi in y_train:\n",
        "    onehot_y_train.append(class_idx[yi])\n",
        "  return np.array(onehot_y_train).copy()"
      ],
      "metadata": {
        "id": "KD33fHH2Mmnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_data(X_train, X_test):\n",
        "  mean = np.mean(X_train, axis=0)\n",
        "  std = np.std(X_train, axis=0)\n",
        "  X_train = (X_train - mean) / std\n",
        "  X_test = (X_test - mean) / std\n",
        "  return X_train, X_test"
      ],
      "metadata": {
        "id": "5st3tdzKpW_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_data(cv_idx): # cv_index = {0, 1, .., 9}\n",
        "  names = [f'fold{i}.csv' for i in range(1, 11)]\n",
        "  X_train = []\n",
        "  X_test = []\n",
        "  y_train = []\n",
        "  y_test = []\n",
        "  for f_idx, name in enumerate(names):\n",
        "    fold_data = pd.read_csv(f'{CUR_PATH}/data/{name}', index_col=0)\n",
        "    fold_X = fold_data.drop([\"filename\", \"class\"], axis=1)\n",
        "    # fold_X = fold_X.drop([f\"mfcc_min{i}\" for i in range(1, 26)], axis=1)\n",
        "    # fold_X = fold_X.drop([f\"mfcc_max{i}\" for i in range(1, 26)], axis=1)\n",
        "    fold_y = fold_data['class'].values.tolist()\n",
        "    fold_X = fold_X.values.tolist()\n",
        "    if f_idx == cv_idx:\n",
        "      X_test.extend(fold_X)\n",
        "      y_test.extend(fold_y)\n",
        "    else:\n",
        "      X_train.extend(fold_X)\n",
        "      y_train.extend(fold_y)\n",
        "  \n",
        "  return np.array(X_train).copy(), np.array(X_test).copy(), y_train, y_test"
      ],
      "metadata": {
        "id": "aA5sGK0YpXH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(cv_idx):\n",
        "  X_train, X_test, y_train, y_test = import_data(cv_idx)\n",
        "  X_train, X_test = standardize_data(X_train, X_test)\n",
        "  y_train, y_test = class2int(y_train), class2int(y_test)\n",
        "  X_train, X_test = pca(X_train, X_test)  \n",
        "  X_train = np.insert(X_train, 0, 1, axis=1)\n",
        "  X_test = np.insert(X_test, 0, 1, axis=1)\n",
        "  return X_train, X_test,y_train,y_test"
      ],
      "metadata": {
        "id": "DwgeuHxRpXO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def pca(X_train, X_test): # X must be standardized\n",
        "  CUTOFF = 90\n",
        "  n, p = X_train.shape\n",
        "  total_variance = (np.linalg.norm(X_train, ord=\"fro\") ** 2) / n\n",
        "  sigma = (X_train.T @ X_train) / n\n",
        "  w, v = np.linalg.eig(sigma)\n",
        "  w_argsort = w.argsort()[::-1]\n",
        "  w[::-1].sort()\n",
        "  v = v[w_argsort]\n",
        "  pve_first_k = 0\n",
        "\n",
        "  project_X_train = X_train @ v\n",
        "  pve_first_k_all = np.zeros((len(v),1))\n",
        "  needed_k = []\n",
        "\n",
        "  for eig_idx in range(len(w)):\n",
        "    pve_first_k += (project_X_train[:,eig_idx].T @ project_X_train[:,eig_idx]) / (n * total_variance)\n",
        "    pve_first_k_all[eig_idx] = pve_first_k\n",
        "    if pve_first_k > CUTOFF / 100:\n",
        "      needed_k.append(eig_idx)\n",
        "\n",
        "  k = needed_k[0]\n",
        "  u = v[:,:k]\n",
        "  X_train = X_train @ u\n",
        "  X_test = X_test @ u\n",
        "\n",
        "  plt.plot(np.linspace(1, p, p),100 * pve_first_k_all)\n",
        "  plt.title('# of PC vs. PVE (%)\\n'\n",
        "            '# of PC where PVE exceeds {0:d}% first time: {1:d}'.format(CUTOFF,k))\n",
        "  plt.xlabel('# of PC')\n",
        "  plt.ylabel('PVE (%)')\n",
        "  plt.plot(k, 100 * pve_first_k_all[k],'rx')\n",
        "  plt.plot(np.linspace(1, p, p), CUTOFF * np.ones(p),'r--')\n",
        "  return X_train, X_test\n"
      ],
      "metadata": {
        "id": "BOacApHl-mOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "import numpy as np\n",
        "def dist(row1, row2):\n",
        "    distance = 0\n",
        "    for i in range(len(row1)):\n",
        "        distance += (row1[i] - row2[i])**2          \n",
        "    return sqrt(distance)"
      ],
      "metadata": {
        "id": "40xJbWPDpXT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def dist2(row1, row2):\n",
        "    return np.linalg.norm(row1 - row2)"
      ],
      "metadata": {
        "id": "-R6vmaheug7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def get_nearest_neighbors(x_train,row_to_search,y_train, k):\n",
        "      \n",
        "        distances, neighbors = [], [] \n",
        "        for i, x_row in enumerate(x_train):\n",
        "            d = dist2(row_to_search, x_row)\n",
        "            distances.append([d,y_train[i], i]) # dist, index\n",
        "        \n",
        "        distances.sort(key = lambda x: x[0])\n",
        "        \n",
        "        for i in range(k):\n",
        "            neighbors.append(distances[i])\n",
        "        \n",
        "        return neighbors"
      ],
      "metadata": {
        "id": "dcZOjjWspXYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def predict( X_test, X_train, Y_train,k):\n",
        "\n",
        "        x_train, y_train = X_train, Y_train\n",
        "\n",
        "        y_predict = []\n",
        "\n",
        "        for x_row in X_test:\n",
        "\n",
        "            neighbors = get_nearest_neighbors(x_train,x_row,Y_train,k)\n",
        "            targets = []\n",
        "            for n in neighbors:\n",
        "                ind = n[2]\n",
        "                targets.append(y_train[ind])\n",
        "\n",
        "            y_predict.append(max(targets, key = targets.count))\n",
        "        y_predict = np.array(y_predict)\n",
        "        return y_predict"
      ],
      "metadata": {
        "id": "imEuqz2FpXcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def eval_metrics(y_preds, y_true):\n",
        "    k = len(classes)\n",
        "    conf_matrix = np.zeros((k, k), dtype=int)\n",
        "    for i in range(len(y_preds)):\n",
        "        conf_matrix[y_true[i], y_preds[i]] += 1\n",
        "\n",
        "    acc = (y_preds == y_true).sum() / len(y_preds)\n",
        "\n",
        "    precision, recall, f1 = np.zeros(k), np.zeros(k), np.zeros(k)\n",
        "\n",
        "    for j in range(k):\n",
        "        precision[j] = conf_matrix[j, j] / np.sum(conf_matrix[:, j]) * 100\n",
        "        recall[j] = conf_matrix[j, j] / np.sum(conf_matrix[j, :]) * 100\n",
        "        f1[j] = 2 * precision[j] * recall[j] / (precision[j] + recall[j])\n",
        "    \n",
        "    conf_matrix = pd.DataFrame(data=conf_matrix, index=classes, columns=classes)\n",
        "    plt.figure(figsize=(10, 8), dpi=100)\n",
        "    plt.title(\"Confusion Matrix - Softmax Regression\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    \n",
        "    precision = [f'{p:.2f}' for p in precision]\n",
        "    recall = [f'{p:.2f}' for p in recall]\n",
        "    f1 = [f'{p:.2f}' for p in f1]\n",
        "    \n",
        "    heatmap = sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt=\"d\")\n",
        "    heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=30)\n",
        "    heatmap.set_xlabel('Predicted Labels', fontsize=12)\n",
        "    heatmap.set_ylabel('True Labels', fontsize=12)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return acc, precision, recall, f1"
      ],
      "metadata": {
        "id": "_6yZXpxffIHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "from pprint import pprint\n",
        "import csv\n",
        "\n",
        "k_list = [6]\n",
        "\n",
        "accuracies = np.zeros(len(k_list))\n",
        "output_lines = []\n",
        "\n",
        "for idx, k in enumerate(k_list):\n",
        "  correct = 0\n",
        "  length = 0\n",
        "  time = 0\n",
        "  y_preds = []\n",
        "  y_true = []\n",
        "  y_train_preds = []\n",
        "  y_train_true = []\n",
        "  for fold_idx in range(0, 10):\n",
        "        X_train, X_test, y_train, y_test = prepare_dataset(fold_idx)\n",
        "        start = timer()\n",
        "        # y_predict = predict(X_test, X_train, y_train, k)\n",
        "        end = timer()\n",
        "        time = time + end - start\n",
        "        y_predict = np.zeros_like(y_test)\n",
        "        # print((y_predict == y_test).sum() / y_test.shape[0])\n",
        "        y_preds.append(y_predict)\n",
        "        y_true.append(y_test)\n",
        "        y_train_preds.append(np.array(predict(X_train, X_train, y_train, k)))\n",
        "        y_train_true.append(y_train)\n",
        "        #correct += (y_predict == y_test).sum()\n",
        "        #length += y_test.shape[0]\n",
        "\n",
        "  y_preds = np.concatenate(y_preds, axis=None)\n",
        "  y_true = np.concatenate(y_true, axis=None)\n",
        "  y_train_preds = np.concatenate(y_train_preds, axis=None)\n",
        "  y_train_true = np.concatenate(y_train_true, axis=None)\n",
        "  acc, precision, recall, f1 = eval_metrics(y_preds, y_true)\n",
        "  train_acc, _, _, _ = eval_metrics(y_train_preds, y_train_true)\n",
        "  accuracies[idx] = acc\n",
        "\n",
        "  with open(f'{CUR_PATH}/eval_metrics_knn.csv', 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    # write the header\n",
        "    writer.writerow([\"Classes\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
        "\n",
        "    # write multiple rows\n",
        "    writer.writerows(zip(classes, precision, recall, f1))\n",
        "\n",
        "  print(f'k: {k}, Train Accuracy: {train_acc:.3f}, Test Accuracy: {acc:.3f}, Time: {time:.3f} seconds')\n",
        "pprint(accuracies)"
      ],
      "metadata": {
        "id": "oyGDN9h7pXjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LfphLApOvEkb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}